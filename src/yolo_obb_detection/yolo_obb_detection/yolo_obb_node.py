#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import String
from cv_bridge import CvBridge
import cv2
import numpy as np
from ultralytics import YOLO
import time
import math
import json
from collections import deque


class YoloObbNode(Node):
    def __init__(self):
        super().__init__('yolo_obb_node')
        
        # íŒŒë¼ë¯¸í„°
        self.declare_parameter('model_path', '/home/xotn/ros2_ws/src/yolo_obb_detection/models/best.pt')
        self.declare_parameter('confidence_threshold', 0.70)
        self.declare_parameter('display_enabled', True)
        
        model_path = self.get_parameter('model_path').get_parameter_value().string_value
        self.conf_threshold = self.get_parameter('confidence_threshold').get_parameter_value().double_value
        self.display_enabled = self.get_parameter('display_enabled').get_parameter_value().bool_value
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        try:
            self.model = YOLO(model_path)
            self.get_logger().info(f'YOLO model loaded: {model_path}')
        except Exception as e:
            self.get_logger().error(f'Failed to load model: {str(e)}')
            return
        
        self.bridge = CvBridge()
        
        # ìµœì‹  ì´ë¯¸ì§€ ì €ì¥ìš©
        self.latest_color_image = None
        self.latest_depth_image = None
        
        # ëìŠ¤ ê°’ ì•ˆì •í™”ë¥¼ ìœ„í•œ ë²„í¼
        self.depth_buffer = deque(maxlen=5)
        
        # êµ¬ë…ìë“¤
        self.color_sub = self.create_subscription(
            Image, '/d415/realsense_d415/color/image_raw', self.color_callback, 1)
        
        self.depth_sub = self.create_subscription(
            Image, '/d415/realsense_d415/depth/image_rect_raw', self.depth_callback, 1)
        
        self.detection_trigger_sub = self.create_subscription(
            String, '/yolo/detection_trigger', self.detection_trigger_callback, 10)
        
        # í¼ë¸”ë¦¬ì…”ë“¤
        self.result_pub = self.create_publisher(Image, '/yolo_result', 1)
        self.detection_result_pub = self.create_publisher(String, '/yolo/detection_result', 10)
        
        # OpenCV ìœˆë„ìš° ì„¤ì •
        if self.display_enabled:
            cv2.namedWindow('YOLO Detection', cv2.WINDOW_AUTOSIZE)
            cv2.namedWindow('Detection Info', cv2.WINDOW_AUTOSIZE)
            self.get_logger().info('ğŸ–¥ï¸ OpenCV ë””ìŠ¤í”Œë ˆì´ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.')
        else:
            self.get_logger().info('ğŸš« OpenCV ë””ìŠ¤í”Œë ˆì´ê°€ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.')
        
        # ì²˜ë¦¬ íƒ€ì´ë¨¸
        self.timer = self.create_timer(0.1, self.process_images)
        
        # ê²€ì¶œ ìš”ì²­ í”Œë˜ê·¸
        self.detection_requested = False
        self.target_name = None
        
        # ë””ìŠ¤í”Œë ˆì´ ì •ë³´ ì €ì¥
        self.display_info = {
            'objects_count': 0,
            'last_detection_time': 0,
            'target': 'None',
            'fps': 0
        }
        self.frame_count = 0
        self.last_fps_time = time.time()
        
        self.get_logger().info('ğŸ¯ YOLO OBB Node started with display')

    def color_callback(self, msg):
        try:
            self.latest_color_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        except Exception as e:
            self.get_logger().error(f'Color callback error: {str(e)}')

    def depth_callback(self, msg):
        try:
            self.latest_depth_image = self.bridge.imgmsg_to_cv2(msg, "16UC1")
        except Exception as e:
            self.get_logger().error(f'Depth callback error: {str(e)}')

    def detection_trigger_callback(self, msg):
        try:
            trigger_data = json.loads(msg.data)
            self.target_name = trigger_data.get('target', 'unknown')
            self.detection_requested = True
            self.display_info['target'] = self.target_name
            self.get_logger().info(f'ğŸ” ê²€ì¶œ ìš”ì²­ ìˆ˜ì‹ : {self.target_name}')
        except json.JSONDecodeError as e:
            self.get_logger().error(f'ê²€ì¶œ íŠ¸ë¦¬ê±° íŒŒì‹± ì˜¤ë¥˜: {e}')

    def get_depth_at_point(self, x, y):
        if self.latest_depth_image is None:
            return None
        
        height, width = self.latest_depth_image.shape
        if 0 <= x < width and 0 <= y < height:
            x_start = max(0, x-2)
            x_end = min(width, x+3)
            y_start = max(0, y-2)
            y_end = min(height, y+3)
            
            depth_region = self.latest_depth_image[y_start:y_end, x_start:x_end]
            valid_depths = depth_region[depth_region > 0]
            
            if len(valid_depths) > 0:
                current_depth = np.median(valid_depths)
                self.depth_buffer.append(current_depth)
                
                if len(self.depth_buffer) >= 3:
                    return np.mean(self.depth_buffer)
                else:
                    return current_depth
        return None

    def pixel_to_robot_coordinates(self, pixel_x, pixel_y):
        robot_x = (1 / 15) * pixel_y - (113 / 15)
        robot_y = (-19 / 286) * pixel_x + (12697 / 286)
        return robot_x, robot_y

    def calculate_fps(self):
        self.frame_count += 1
        current_time = time.time()
        if current_time - self.last_fps_time >= 1.0:
            self.display_info['fps'] = self.frame_count / (current_time - self.last_fps_time)
            self.frame_count = 0
            self.last_fps_time = current_time

    def create_info_display(self):
        info_img = np.zeros((300, 400, 3), dtype=np.uint8)
        
        # # ì œëª©
        # cv2.putText(info_img, 'YOLO Detection Info', (10, 30), 
        #            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        # êµ¬ë¶„ì„ 
        cv2.line(info_img, (10, 40), (390, 40), (255, 255, 255), 1)
        
        # # ì •ë³´ í‘œì‹œ
        # y_pos = 70
        # info_lines = [
        #     f"Target: {self.display_info['target']}",
        #     f"Objects Count: {self.display_info['objects_count']}",
        #     f"FPS: {self.display_info['fps']:.1f}",
        #     f"Detection Requested: {'Yes' if self.detection_requested else 'No'}",
        #     "",
        #     "Controls:",
        #     "ESC - Exit",
        #     "SPACE - Manual trigger",
        #     "R - Reset info"
        # ]
        
        # for i, line in enumerate(info_lines):
        #     color = (0, 255, 0) if i < 4 else (200, 200, 200)
        #     cv2.putText(info_img, line, (10, y_pos + i * 25), 
        #                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        return info_img

    def correct_rotation_with_hsv(self, image, obb_points, center_x, center_y):
        """HSV ê¸°ë°˜ìœ¼ë¡œ íšŒì „ ê°ë„ ë³´ì • - ë²„ê·¸ ìˆ˜ì •"""
        
        try:
            # ROI ì˜ì—­ í™•ì¥ (ì—¬ìœ  ê³µê°„ í™•ë³´)
            x, y, w, h = cv2.boundingRect(obb_points)
            margin = 20
            roi_y_start = max(0, y-margin)
            roi_y_end = min(image.shape[0], y+h+margin)
            roi_x_start = max(0, x-margin)
            roi_x_end = min(image.shape[1], x+w+margin)
            
            roi = image[roi_y_start:roi_y_end, roi_x_start:roi_x_end]
            
            # ROIê°€ ìœ íš¨í•œì§€ í™•ì¸
            if roi.shape[0] <= 0 or roi.shape[1] <= 0:
                self.get_logger().debug('ROI í¬ê¸°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ')
                return None
            
            # HSV ë³€í™˜
            hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
            
            # **ìˆ˜ì •ëœ ë¶€ë¶„**: ROIì˜ ì‹¤ì œ í¬ê¸° ì‚¬ìš©
            roi_h, roi_w = roi.shape[:2]
            if roi_h <= 0 or roi_w <= 0:
                self.get_logger().debug('ROI í¬ê¸°ê°€ 0 ì´í•˜')
                return None
                
            # ROI ì¤‘ì‹¬ì ì˜ ìƒ‰ìƒ (ìˆ˜ì •ëœ ì¸ë±ìŠ¤ ì‚¬ìš©)
            roi_center_color = hsv[roi_h//2, roi_w//2]
            
            # HSV ë²”ìœ„ ì„¤ì • - ë” ë„“ì€ ë²”ìœ„ë¡œ ì„¤ì •
            hue = roi_center_color[0]
            sat = roi_center_color[1] 
            val = roi_center_color[2]
            
            # ë¬´ì±„ìƒ‰ ê°ì²´ ì²˜ë¦¬
            if sat < 30:  # ì±„ë„ê°€ ë‚®ìœ¼ë©´ ë°ê¸° ê¸°ë°˜ìœ¼ë¡œ
                lower_hsv = np.array([0, 0, max(0, val - 40)])
                upper_hsv = np.array([180, 255, min(255, val + 40)])
            else:  # ìœ ì±„ìƒ‰ ê°ì²´
                lower_hsv = np.array([max(0, hue - 30), 30, 30])
                upper_hsv = np.array([min(180, hue + 30), 255, 255])
            
            # ë§ˆìŠ¤í¬ ìƒì„±
            color_mask = cv2.inRange(hsv, lower_hsv, upper_hsv)
            
            # ë…¸ì´ì¦ˆ ì œê±°
            kernel = np.ones((3, 3), np.uint8)
            color_mask = cv2.morphologyEx(color_mask, cv2.MORPH_OPEN, kernel)
            color_mask = cv2.morphologyEx(color_mask, cv2.MORPH_CLOSE, kernel)
            
            # ì»¨íˆ¬ì–´ ì°¾ê¸°
            contours, _ = cv2.findContours(color_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                # ê°€ì¥ í° ì»¨íˆ¬ì–´ ì„ íƒ
                largest_contour = max(contours, key=cv2.contourArea)
                
                # ì»¨íˆ¬ì–´ í¬ê¸° ê²€ì¦
                area = cv2.contourArea(largest_contour)
                if area < 50:  # ì„ê³„ê°’ì„ 50ìœ¼ë¡œ ë‚®ì¶¤
                    self.get_logger().debug(f'ì»¨íˆ¬ì–´ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ: {area}')
                    return None
                
                # MinAreaRectë¡œ ì •í™•í•œ íšŒì „ê° ê³„ì‚°
                rect = cv2.minAreaRect(largest_contour)
                corrected_angle = rect[2]
                
                # ê°ë„ ë³´ì •
                if rect[1][0] < rect[1][1]:  # width < height
                    corrected_angle += 90
                
                # 0-360ë„ ë²”ìœ„ë¡œ ì •ê·œí™”
                if corrected_angle < 0:
                    corrected_angle += 360
                elif corrected_angle >= 360:
                    corrected_angle -= 360
                
                self.get_logger().debug(f'HSV ë³´ì • ì„±ê³µ: {corrected_angle:.1f}ë„ (ì»¨íˆ¬ì–´ í¬ê¸°: {area:.1f})')
                return corrected_angle
            else:
                self.get_logger().debug('ìœ íš¨í•œ ì»¨íˆ¬ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ')
                return None
                
        except Exception as e:
            self.get_logger().warn(f'HSV ë³´ì • ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}')
            return None

    def calculate_correction_confidence(self, yolo_angle, corrected_angle):
        if corrected_angle is None:
            return 0.0
        
        angle_diff = abs(yolo_angle - corrected_angle)
        if angle_diff > 180:
            angle_diff = 360 - angle_diff
        
        confidence = max(0, 1 - angle_diff / 90.0)
        return confidence

    def process_images(self):
        if self.latest_color_image is None:
            return
        try:
            self.calculate_fps()
            
            results = self.model.predict(source=self.latest_color_image, imgsz=640, conf=self.conf_threshold, verbose=False)
            
            if results[0].obb is not None:
                self.display_info['objects_count'] = len(results[0].obb)
            else:
                self.display_info['objects_count'] = 0
            
            annotated = self.draw_results(self.latest_color_image, results[0])
            
            if self.detection_requested:
                self.publish_detection_results(results[0])
                self.detection_requested = False
                self.display_info['last_detection_time'] = time.time()
            
            if self.display_enabled:
                cv2.imshow('YOLO Detection', annotated)
                
                info_display = self.create_info_display()
                cv2.imshow('Detection Info', info_display)
                
                key = cv2.waitKey(1) & 0xFF
                if key == 27:  # ESC
                    self.get_logger().info('ESC pressed, shutting down...')
                    rclpy.shutdown()
                elif key == ord(' '):  # SPACE
                    self.detection_requested = True
                    self.get_logger().info('ğŸ” ìˆ˜ë™ ê²€ì¶œ íŠ¸ë¦¬ê±°')
                elif key == ord('r') or key == ord('R'):  # R
                    self.display_info = {
                        'objects_count': 0,
                        'last_detection_time': 0,
                        'target': 'None',
                        'fps': 0
                    }
                    self.get_logger().info('ğŸ“Š ì •ë³´ ë¦¬ì…‹')
            
            try:
                result_msg = self.bridge.cv2_to_imgmsg(annotated, "bgr8")
                self.result_pub.publish(result_msg)
            except Exception as e:
                self.get_logger().error(f'Result image publish error: {str(e)}')
            
        except Exception as e:
            self.get_logger().error(f'Processing error: {str(e)}')

    def publish_detection_results(self, result):
        detected_objects = []
        
        if result.obb is not None and len(result.obb) > 0:
            obb_coords = result.obb.xyxyxyxy.cpu().numpy()
            
            for i, coords in enumerate(obb_coords):
                points = coords.reshape(4, 2).astype(np.int32)
                
                len_side1 = np.linalg.norm(points[1] - points[0])
                len_side2 = np.linalg.norm(points[2] - points[1])
                
                if len_side1 <= len_side2:
                    yolo_angle = math.degrees(math.atan2(points[1][1] - points[0][1], points[1][0] - points[0][0]))
                else:
                    yolo_angle = math.degrees(math.atan2(points[2][1] - points[1][1], points[2][0] - points[1][0]))
                
                if yolo_angle < 0:
                    yolo_angle += 360
                
                center_x = np.mean(points[:, 0])
                center_y = np.mean(points[:, 1])
                
                try:
                    corrected_angle = self.correct_rotation_with_hsv(
                        self.latest_color_image, points, center_x, center_y)
                    
                    confidence = self.calculate_correction_confidence(yolo_angle, corrected_angle)
                    final_angle = corrected_angle if (corrected_angle is not None and confidence > 0.3) else yolo_angle
                    
                except Exception as e:
                    self.get_logger().warn(f'HSV ë³´ì • ì‹¤íŒ¨: {str(e)}')
                    corrected_angle = None
                    confidence = 0.0
                    final_angle = yolo_angle
                
                depth_mm = self.get_depth_at_point(int(center_x), int(center_y))
                robot_x, robot_y = self.pixel_to_robot_coordinates(center_x, center_y)
                
                detected_object = {
                    'id': i,
                    'pixel_x': float(center_x),
                    'pixel_y': float(center_y),
                    'yolo_angle': float(yolo_angle),
                    'corrected_angle': float(corrected_angle) if corrected_angle is not None else None,
                    'final_angle': float(final_angle),
                    'correction_confidence': float(confidence),
                    'depth_mm': float(depth_mm) if depth_mm is not None else None,
                    'robot_x': float(robot_x),
                    'robot_y': float(robot_y)
                }
                
                detected_objects.append(detected_object)
                
                if corrected_angle is not None:
                    self.get_logger().info(
                        f'ğŸ¯ ë³´ì • ê²°ê³¼ #{i+1}: YOLO({yolo_angle:.0f}Â°) â†’ HSVë³´ì •({corrected_angle:.0f}Â°) â†’ ìµœì¢…({final_angle:.0f}Â°) [ì‹ ë¢°ë„: {confidence:.2f}]'
                    )
                else:
                    self.get_logger().info(
                        f'ğŸ“ ê²€ì¶œ ê²°ê³¼ #{i+1}: YOLO({yolo_angle:.0f}Â°) â†’ HSVë³´ì • ì‹¤íŒ¨ â†’ ìµœì¢…({final_angle:.0f}Â°)'
                    )
        
        result_msg = String()
        result_data = {
            'target': self.target_name,
            'timestamp': time.time(),
            'objects': detected_objects
        }
        result_msg.data = json.dumps(result_data)
        self.detection_result_pub.publish(result_msg)
        
        self.get_logger().info(f'âœ… ê²€ì¶œ ê²°ê³¼ ë°œí–‰: {len(detected_objects)}ê°œ ê°ì²´ (HSV ë³´ì • í¬í•¨)')

    def draw_results(self, image, result):
        annotated = image.copy()
        
        overlay = annotated.copy()
        cv2.rectangle(overlay, (0, 0), (annotated.shape[1], 80), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, annotated, 0.3, 0, annotated)
        
        # # putText ëª¨ë‘ ì£¼ì„ì²˜ë¦¬
        # cv2.putText(annotated, f"Target: {self.display_info['target']} | Objects: {self.display_info['objects_count']} | FPS: {self.display_info['fps']:.1f}", 
        #         (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # status = "DETECTING..." if self.detection_requested else "MONITORING"
        # status_color = (0, 255, 255) if self.detection_requested else (0, 255, 0)
        # cv2.putText(annotated, f"Status: {status} | HSV Correction: ON", (10, 55), 
        #         cv2.FONT_HERSHEY_SIMPLEX, 0.6, status_color, 2)
        
        if result.obb is not None and len(result.obb) > 0:
            obb_coords = result.obb.xyxyxyxy.cpu().numpy()
            
            for i, coords in enumerate(obb_coords):
                points = coords.reshape(4, 2).astype(np.int32)
                
                len_side1 = np.linalg.norm(points[1] - points[0])
                len_side2 = np.linalg.norm(points[2] - points[1])
                
                if len_side1 <= len_side2:
                    yolo_angle = math.degrees(math.atan2(points[1][1] - points[0][1], points[1][0] - points[0][0]))
                else:
                    yolo_angle = math.degrees(math.atan2(points[2][1] - points[1][1], points[2][0] - points[1][0]))
                
                if yolo_angle < 0:
                    yolo_angle += 360
                
                center_x = np.mean(points[:, 0])
                center_y = np.mean(points[:, 1])
                
                corrected_angle = self.correct_rotation_with_hsv(image, points, center_x, center_y)
                confidence = self.calculate_correction_confidence(yolo_angle, corrected_angle)
                
                colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]
                color = colors[i % len(colors)]
                
                cv2.polylines(annotated, [points], True, color, 3)
                
                cv2.circle(annotated, (int(center_x), int(center_y)), 8, (0, 0, 255), -1)
                cv2.circle(annotated, (int(center_x), int(center_y)), 12, (255, 255, 255), 2)
                
                final_angle = corrected_angle if (corrected_angle is not None and confidence > 0.3) else yolo_angle
                arrow_length = 40
                end_x = int(center_x + arrow_length * math.cos(math.radians(final_angle)))
                end_y = int(center_y + arrow_length * math.sin(math.radians(final_angle)))
                cv2.arrowedLine(annotated, (int(center_x), int(center_y)), (end_x, end_y), (0, 255, 255), 3, tipLength=0.3)
                
                # # ê°ì²´ ë²ˆí˜¸ì™€ ê°ë„ ì •ë³´ í…ìŠ¤íŠ¸ë„ ì£¼ì„ì²˜ë¦¬
                # cv2.putText(annotated, f"#{i+1}", (int(center_x) - 30, int(center_y) - 30),
                #         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                
                # yolo_info = f"YOLO: {yolo_angle:.0f}deg"
                # hsv_info = f"HSV: {corrected_angle:.0f}deg ({confidence:.2f})" if corrected_angle is not None else "HSV: Failed"
                # final_info = f"Final: {final_angle:.0f}deg"
                
                # bg_height = 75
                # cv2.rectangle(annotated, 
                #             (int(center_x) - 80, int(center_y) + 15), 
                #             (int(center_x) + 120, int(center_y) + 15 + bg_height),
                #             (0, 0, 0), -1)
                
                # cv2.putText(annotated, yolo_info, (int(center_x) - 75, int(center_y) + 35),
                #         cv2.FONT_HERSHEY_SIMPLEX, 0.45, (100, 100, 255), 1)
                # cv2.putText(annotated, hsv_info, (int(center_x) - 75, int(center_y) + 55),
                #         cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 255) if corrected_angle else (100, 100, 100), 1)
                # cv2.putText(annotated, final_info, (int(center_x) - 75, int(center_y) + 75),
                #         cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 1)
        
        # ì¤‘ì•™ ì‹­ìì„ ì€ ìœ ì§€
        h, w = annotated.shape[:2]
        cv2.line(annotated, (w//2 - 20, h//2), (w//2 + 20, h//2), (255, 255, 255), 2)
        cv2.line(annotated, (w//2, h//2 - 20), (w//2, h//2 + 20), (255, 255, 255), 2)
        
        return annotated


def main(args=None):
    rclpy.init(args=args)
    
    try:
        node = YoloObbNode()
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        if 'node' in locals():
            node.destroy_node()
        cv2.destroyAllWindows()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
